{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Mistral-7b in Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook describes the process of fine-tuning Mistral-7B model, available in Azure Machine Learning's system registry, on Azure GPU compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Configuring Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install required Azure AI and Azure Identity Python packages:\n",
    "```\n",
    "pip install azure-ai-ml azure-identity mlflow azureml-mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import uuid\n",
    "import time\n",
    "import requests\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.finetuning import (\n",
    "    FineTuningTaskType,\n",
    "    create_finetuning_job\n",
    ")\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    ProbeSettings,\n",
    "    OnlineRequestSettings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set required variable values\n",
    "subscription_id = \"<your_subscription_id>\"\n",
    "resource_group = \"<your_resource_group>\"\n",
    "workspace_name = \"<your_workspace_name>\"\n",
    "model_registry = \"<your_model_registry_name>\"\n",
    "model_name = \"<your_model_name>\"\n",
    "training_dataset_name = \"<your_dataset_name>\"\n",
    "training_dataset_file = \"<your_dataset_file_name>\"\n",
    "validation_dataset_name = \"<your_validation_dataset_name>\"\n",
    "validation_dataset_file = \"<your_validation_dataset_file_name>\"\n",
    "dataset_version = \"<your_dataset_version>\"\n",
    "job_name = \"<your_job_name>\"\n",
    "job_compute = \"<your_job_compute>\"\n",
    "endpoint_name = \"<your_endpoint_name>\"\n",
    "endpoint_SKU = \"<your_endpoint_SKU>\"\n",
    "guid = str(uuid.uuid4())[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Default Azure Credentials, or fallback to Interactive Browser Credentials\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise AML workspace client\n",
    "workspace_ml_client = MLClient(\n",
    "    credential = credential,\n",
    "    subscription_id = subscription_id,\n",
    "    resource_group_name = resource_group,\n",
    "    workspace_name = workspace_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise AML registry client\n",
    "registry_ml_client = MLClient(\n",
    "    credential = credential,\n",
    "    registry_name = model_registry\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Defining Source Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve model details from AML Registry\n",
    "model_to_finetune = registry_ml_client.models.get(\n",
    "    name = model_name,\n",
    "    label = \"latest\"\n",
    ")\n",
    "\n",
    "print(f\"Model name: {model_to_finetune.name}\")\n",
    "print(f\"Model version: {model_to_finetune.version}\")\n",
    "print(f\"Model ID: {model_to_finetune.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check supported compute SKUs\n",
    "model_to_finetune.properties[\"finetune-recommended-sku\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Preparing Training and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise training dataset\n",
    "try:\n",
    "    train_data_asset = workspace_ml_client.data.get(\n",
    "        name = training_dataset_name,\n",
    "        version = dataset_version\n",
    "    )\n",
    "    print(f\"Dataset {training_dataset_name} already exists! Will re-use it.\")\n",
    "except:\n",
    "    print(\"Creating dataset..\\n\")\n",
    "    train_data = Data(\n",
    "        path = f\"./{training_dataset_file}\",\n",
    "        type = AssetTypes.URI_FILE,\n",
    "        description = \"Training dataset\",\n",
    "        name = training_dataset_name,\n",
    "        version = dataset_version\n",
    "    )\n",
    "    train_data_asset = workspace_ml_client.data.create_or_update(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training dataset details\n",
    "print(f\"Dataset name: {train_data_asset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise validation dataset\n",
    "try:\n",
    "    val_data_asset = workspace_ml_client.data.get(\n",
    "        name = validation_dataset_name,\n",
    "        version = dataset_version\n",
    "    )\n",
    "    print(f\"Dataset {validation_dataset_name} already exists! Will re-use it.\")\n",
    "except:\n",
    "    print(\"Creating dataset..\\n\")\n",
    "    val_data = Data(\n",
    "        path = f\"./{validation_dataset_file}\",\n",
    "        type = AssetTypes.URI_FILE,\n",
    "        description = \"Validation dataset\",\n",
    "        name = validation_dataset_name,\n",
    "        version = dataset_version\n",
    "    )\n",
    "    val_data_asset = workspace_ml_client.data.create_or_update(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check validation dataset details\n",
    "print(f\"Dataset name: {val_data_asset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fine-tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fine-tuning job\n",
    "finetuning_job = create_finetuning_job(\n",
    "    name = f\"{job_name}-{guid}\",\n",
    "    display_name = f\"{job_name}-{guid}\",\n",
    "    experiment_name = f\"Finetuning-{model_name}\",\n",
    "    model = model_to_finetune.id,\n",
    "    task = FineTuningTaskType.TEXT_COMPLETION,\n",
    "    training_data = train_data_asset.id,\n",
    "    validation_data = val_data_asset.id,\n",
    "    output_model_name_prefix = f\"{model_name}-finetuned-{guid}\",\n",
    "    compute = job_compute,\n",
    "    # instance_types = [\"Standard_ND96amsr_A100_v4\", \"Standard_E4s_v3\"],\n",
    "    hyperparameters = {\n",
    "        \"per_device_train_batch_size\": \"1\",\n",
    "        \"learning_rate\": \"0.00002\",\n",
    "        \"num_train_epochs\": \"1\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit fine-tuning job\n",
    "created_job = workspace_ml_client.jobs.create_or_update(finetuning_job)\n",
    "workspace_ml_client.jobs.get(created_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor fine-tuning job status\n",
    "status = workspace_ml_client.jobs.get(created_job.name).status\n",
    "\n",
    "while True:\n",
    "    status = workspace_ml_client.jobs.get(created_job.name).status\n",
    "    \n",
    "    if status in [\"Failed\", \"Completed\", \"Canceled\"]:\n",
    "        print(\"Job has finished with status: {0}\".format(status))\n",
    "        break\n",
    "    else:\n",
    "        print(\"Job run is in progress. Checking again in 30 seconds..\")\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify fine-tuning job output\n",
    "registered_model_output = created_job.outputs[\"registered_model\"]\n",
    "\n",
    "print(f\"Finetuning job's output: {registered_model_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check registered model\n",
    "registered_models = workspace_ml_client.models.list()\n",
    "\n",
    "for model in registered_models:\n",
    "    if model.name.startswith(model_name):\n",
    "        registered_model = model\n",
    "        print(f\"Registered fine-tuned model name: {registered_model.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Deploying Finetuned Model to Online Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name = endpoint_name,\n",
    "    description = f\"Online endpoint for {registered_model.name}\",\n",
    "    auth_mode=\"key\"\n",
    ")\n",
    "\n",
    "workspace_ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check supported inference SKUs\n",
    "model_to_finetune.properties[\"inference-recommended-sku\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get deployable model\n",
    "deploy_model = workspace_ml_client.models.get(\n",
    "    name = registered_model.name,\n",
    "    version = registered_model.latest_version\n",
    ")\n",
    "\n",
    "print(f\"Deployable model name: {deploy_model.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create online deployment\n",
    "ft_deployment = ManagedOnlineDeployment(\n",
    "    name = \"finetunedmodel\",\n",
    "    endpoint_name = endpoint_name,\n",
    "    model = deploy_model.id,\n",
    "    instance_type = endpoint_SKU,\n",
    "    instance_count = 1,\n",
    "    liveness_probe = ProbeSettings(initial_delay=600),\n",
    "    request_settings = OnlineRequestSettings(request_timeout_ms=90000),\n",
    ")\n",
    "\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(ft_deployment).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate traffic to deployment\n",
    "endpoint.traffic = {\n",
    "    \"finetunedmodel\": 100\n",
    "}\n",
    "\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get endpoint auth key\n",
    "auth_key = workspace_ml_client.online_endpoints.get_keys(endpoint_name).primary_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get endpoint URL\n",
    "my_endpoint = workspace_ml_client.online_endpoints.get(name=endpoint_name)\n",
    "scoring_uri = my_endpoint.scoring_uri\n",
    "print(f\"Endpoint URL: {scoring_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test deployed model\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": (\"Bearer \"+ auth_key)}\n",
    "url = scoring_uri.replace(\"/score\", \"/completions\")\n",
    "prompt = \"Summarize the dialog.\\n<dialog>: Edward: Rachel, at what time is the meeting..\\r\\nRachel: At 2pm..\\r\\nEdward: Ok, see you then\\n<summary>: \"\n",
    "payload = {\n",
    "    \"prompt\": prompt,\n",
    "    \"temperature\": 0,\n",
    "    \"max_tokens\": 200,\n",
    "}\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "print(f\"Response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautify response\n",
    "structured_response = response.json()\n",
    "print(\"----------------\")\n",
    "print(f\"Prompt used: {prompt}\\n\")\n",
    "print(f\"Model's response: {structured_response['choices'][0]['text']}\")\n",
    "print(\"----------------\")\n",
    "print(f\"Prompt token count: {structured_response['usage']['prompt_tokens']}\")\n",
    "print(f\"Response token count: {structured_response['usage']['completion_tokens']}\")\n",
    "print(f\"Total token count: {structured_response['usage']['total_tokens']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
